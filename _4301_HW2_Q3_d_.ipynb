{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "-- 4301 -- HW2 -- Q3.d -- .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBYq4uF4Ao9p9rtqpOd0Lx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahabshms/Numerical_Methods_for_ML_and_AI_Solution_2/blob/main/_4301_HW2_Q3_d_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhuGi01K0nJ2"
      },
      "source": [
        "# Problem 3.d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhqG0SuU4O1M"
      },
      "source": [
        "In Python, implement the Frank-Wolfe algorithm to maximize your dual in (c). Your\n",
        "Python function should take as input the $x$’s, the $y$’s, $\\gamma$, the query point $x$, a feasible\n",
        "initial point for the Lagrange multipliers, a tolerance \u000f that terminates the Frank-Wolfe\n",
        "algorithm whenever the convergence criteria from class is met, and an upper bound\n",
        "max it on the number of iterations, and returns the best function value found during\n",
        "the iterative procedure. Hint: you can analytically eliminate the Lagrange multiplier\n",
        "corresponding to the constraint $\\Vert w\\Vert_2^2 \\leq \\gamma^2$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIlathtT4hHW"
      },
      "source": [
        "\n",
        "From the previous section\n",
        "\\begin{align*}\n",
        "    g(\\lambda) &= -\\sum_{m=1}^{M} \\lambda_m ( y^{(m)} - w_0^T(x^{(m)} - q)) +  \\lambda_{M+1}(\\Vert w_0 \\Vert^2_2 - \\gamma^2)\n",
        "\\end{align*}\n",
        "such that \n",
        "$$w_0 = \\frac{\\sum_{m=1}^M \\lambda_m(q - x^{(m)})}{2\\lambda_{M+1}}$$\n",
        "$$\\sum_{m=1}^M \\lambda_m = 1$$\n",
        "$$\\lambda \\succeq \\boldsymbol{0}$$\n",
        "\n",
        "So\n",
        "\\begin{align*}\n",
        "    g(\\lambda) &= -\\sum_{m=1}^{M} \\lambda_m y^{(m)} - \\sum_{m=1}^M \\lambda_m w_0^T(x^{(m)} - q) +  \\lambda_{M+1}(\\Vert w_0 \\Vert^2_2 - \\gamma^2)\\\\\n",
        "    &= -\\sum_{m=1}^{M} \\lambda_m y^{(m)} - \\frac{1}{4\\lambda_{M+1}}\\sum_{m=1}^M\\sum_{k=1}^M \\left(\\lambda_m\\lambda_k (x^{(m)} - q)^T(x^{(k)}-q)\\right) -  \\lambda_{M+1}\\gamma^2\n",
        "\\end{align*}\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial g(\\lambda)}{\\partial \\lambda_{M+1}} = \\frac{1}{4\\lambda_{M+1}^2}\\sum_{m=1}^M\\sum_{k=1}^M \\left(\\lambda_m\\lambda_k (x^{(m)} - q)^T(x^{(k)}-q)\\right) -  \\gamma^2 = 0\n",
        "\\end{align}\n",
        "$$\\lambda_{M+1} = \\sqrt{\\frac{1}{4\\gamma^2}\\sum_{m=1}^M\\sum_{k=1}^M \\left(\\lambda_m\\lambda_k (x^{(m)} - q)^T(x^{(k)}-q)\\right)}$$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO128lF30AOn",
        "colab": {
          "background_save": true
        },
        "outputId": "55f5c9c2-e074-402a-8662-787dc1885478"
      },
      "source": [
        "def gradient_descent(initial_point,max_iterations)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello d\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}